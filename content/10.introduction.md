## Introduction

Despite significant advancements in technology, the comprehension of biological and biomedical systems continues to present substantial obstacles (Gallagher, Infinite Possibilities; Advances in Bioscience).
The quantity of data points we collect has grown exponentially, now featuring unparalleled levels of detail.
However, the analysis and interpretation of this vast amount of data have become the primary hurdles to effectively utilizing it (Advances in Bioscience).
One contributing factor to these challenges is the inherent limitations of human knowledge (DOI: 10.1016/j.tics.2005.04.010).
Even the most experienced experts in the field cannot fully grasp the implications of every gene, molecule, symptom, or biomarker.
Furthermore, the occurrence of biological events often depends on specific contexts, such as a particular cell type or disease.

Large Language Models (LLMs) today have the capability to tap into vast pools of knowledge, though this knowledge is intricately woven into their billions of parameters, making it not immediately understandable [@doi:10.48550/arxiv.2204.02311;@doi:10.48550/arxiv.2201.08239;@doi:10.48550/arxiv.2303.08774;@doi:10.1609/aaai.v36i11.21488].
When trained effectively, these models can retrieve and synthesize an almost infinite amount of information from their training data.
The impact of LLMs has been profound, and they are now commonly used by biomedical researchers for a variety of tasks, both general and research-specific [@doi:10.1038/s41586-023-06792-0;@doi:10.1101/2023.04.16.537094;@doi:10.1038/s41587-023-01789-6].
However, the interaction with LLMs is mostly done by hand, which is not only hard to replicate but also unpredictable in outcomes.
One notable issue is their tendency to fabricate information, presenting made-up facts as truth in a very persuasive manner [@doi:10.1038/s41586-023-05881-4;@doi:10.1038/s41587-023-01789-6].
Efforts to move towards more advanced AI, or Artificial General Intelligence, include combining multiple models [@{https://python.langchain.com}] and equipping them with the capability to remember information over longer periods [@{https://autogpt.net/}].
Despite these advancements, trust in AI systems for biomedical applications remains low [@doi:10.1038/s41586-023-05881-4].
The biomedical field requires a high level of attention to data privacy, licensing, and transparency, areas where current AI systems need more oversight to be deemed reliable [@doi:10.48550/arXiv.2401.05654].

Computational biomedicine encompasses a variety of tasks that can benefit from the assistance of Large Language Models (LLMs), including designing experiments, interpreting outcomes, evaluating literature, and exploring web resources.
To enhance and expedite these tasks, we have introduced BioChatter, a platform specifically tailored for facilitating communication between researchers and LLMs in the field of biomedical research (see Figure @fig:overview).
This platform is designed to intuitively guide researchers through their interactions with the model, while also addressing and mitigating any problematic behaviors exhibited by the LLMs.
Given that the primary mode of interaction is through plain text, which can be in any language, the platform is accessible to a broad range of researchers.

<!-- Figure 1 -->
![
**The BioChatter composable platform architecture (simplified).**
LLMs can facilitate many tasks in daily biomedical research practice, for instance interpretation of experimental results or the use of a web resource (top left).
BioChatterâ€™s main response circuit (blue) composes a number of specifically engineered prompts and passes them (and a conversation history) to the primary LLM, which generates a response for the user based on all inputs.
This response is simultaneously used to prompt the secondary circuit (orange), which fulfils auxiliary tasks to complement the primary response.
In particular, using search, the secondary circuit queries a database as a prior knowledge repository and compares annotations to the primary response, or uses the knowledge to perform Retrieval-Augmented Generation (RAG).
A knowledge graph such as BioCypher [@biocypher] can similarly serve as knowledge resource or long-term memory extension of the model.
Further, an independent LLM receives the primary response for fact-checking, which can be supplemented with context-specific information by a RAG process.
The platform is composable in most aspects, allowing arbitrary extensions to other specialised models for additional tasks orchestrated by the primary LLM.
](images/biochatter_overview.png "Overview"){#fig:overview}
